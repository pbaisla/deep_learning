{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7c6788aef474ca12",
      "metadata": {
        "collapsed": false,
        "id": "7c6788aef474ca12"
      },
      "source": [
        "# Creative Text Generation with Recurrent Neural Networks (RNNs)\n",
        "\n",
        "In this assignment, you'll build upon your understanding of RNNs and Keras to develop a word-level text generation model.  Your goal is to train a model that learns the stylistic nuances of a chosen corpus and generates new, original text segments that echo the source material's essence.\n",
        "\n",
        "**Datasets**\n",
        "\n",
        "We've provided several intriguing text corpora to get you started:\n",
        "\n",
        "*   Mark Twain\n",
        "*   Charles Dickens\n",
        "*   William Shakespeare\n",
        "\n",
        "**Feel free to explore!**  If you have a particular passion for another author, genre, or a specific text, you're encouraged to use your own dataset of raw text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2d0bfedcfe52aedc",
      "metadata": {
        "id": "2d0bfedcfe52aedc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-09 12:07:24.116793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-03-09 12:07:24.130366: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-03-09 12:07:24.135207: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-09 12:07:24.231996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1741536446.740048 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536446.926086 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536446.929255 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536447.071198 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536447.072547 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536447.074555 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-03-09 12:07:27.076119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 5727 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
            "I0000 00:00:1741536447.076837 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536447.078407 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536447.079582 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536447.080731 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1741536447.081872 1017792 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-03-09 12:07:27.082970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 5727 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# Check if we have a GPU available\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"No GPU available. If you're on Colab, go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9c28c497f620b775",
      "metadata": {
        "id": "9c28c497f620b775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose a book to download:\n",
            "1: Charles Dickens\n",
            "2: Mark Twain\n",
            "3: William Shakespeare\n",
            "Downloaded charles_dickens.txt successfully!\n",
            "Dataset loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_file(book_name):\n",
        "    base_url = \"https://raw.githubusercontent.com/UofT-DSI/deep_learning/refs/heads/main/02_activities/assignments/downloaded_books/\"\n",
        "    file_url = base_url + book_name\n",
        "    local_filename = book_name\n",
        "\n",
        "    response = requests.get(file_url)\n",
        "    if response.status_code == 200:\n",
        "        with open(local_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(response.text)\n",
        "        print(f\"Downloaded {book_name} successfully!\")\n",
        "        return local_filename\n",
        "    else:\n",
        "        raise ValueError(\"Failed to download the file. Please check the filename and try again.\")\n",
        "\n",
        "def load_dataset(file_path, fraction=1.0):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        raw_text = f.read()\n",
        "    return raw_text[:int(fraction * len(raw_text))]\n",
        "\n",
        "# Prompt user to select a book\n",
        "title_options = {\n",
        "    \"1\": \"charles_dickens.txt\",\n",
        "    \"2\": \"mark_twain.txt\",\n",
        "    \"3\": \"shakespeare.txt\"\n",
        "}\n",
        "\n",
        "print(\"Choose a book to download:\")\n",
        "print(\"1: Charles Dickens\")\n",
        "print(\"2: Mark Twain\")\n",
        "print(\"3: William Shakespeare\")\n",
        "\n",
        "choice = None\n",
        "while choice not in title_options:\n",
        "    choice = input(\"Enter the number corresponding to your choice (1, 2, or 3): \").strip()\n",
        "    if choice not in title_options:\n",
        "        print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
        "\n",
        "selected_book = title_options[choice]\n",
        "file_path = download_file(selected_book)\n",
        "\n",
        "# Load chosen dataset\n",
        "fraction = 0.1  # Adjust fraction if running out of memory\n",
        "text = load_dataset(file_path, fraction=fraction)\n",
        "\n",
        "print(\"Dataset loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab51c764031e606",
      "metadata": {
        "collapsed": false,
        "id": "dab51c764031e606"
      },
      "source": [
        "# 1. Data Preparation (10 Marks)\n",
        "\n",
        "Before we can begin training an RNN model, we need to prepare the dataset. This involves cleaning the text, tokenizing words, and creating sequences the model can be trained on.\n",
        "\n",
        "## 1.1 Data Exploration (3 Marks)\n",
        "\n",
        "Print the first 1000 characters of the dataset. Report the dataset's size and the number of unique characters it contains."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "BunkZmdkl0Wn",
      "metadata": {
        "id": "BunkZmdkl0Wn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Project Gutenberg eBook of A Tale of Two Cities, by Charles Dickens\n",
            "\n",
            "This eBook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this eBook or online at\n",
            "www.gutenberg.org. If you are not located in the United States, you\n",
            "will have to check the laws of the country where you are located before\n",
            "using this eBook.\n",
            "\n",
            "Title: A Tale of Two Cities\n",
            "       A Story of the French Revolution\n",
            "\n",
            "Author: Charles Dickens\n",
            "\n",
            "Release Date: January, 1994 [eBook #98]\n",
            "[Most recently updated: December 20, 2020]\n",
            "\n",
            "Language: English\n",
            "\n",
            "Character set encoding: UTF-8\n",
            "\n",
            "Produced by: Judith Boss and David Widger\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK A TALE OF TWO CITIES ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "A TALE OF TWO CITIES\n",
            "\n",
            "A STORY OF THE FRENCH REVOLUTION\n",
            "\n",
            "By Charles Dickens\n",
            "\n",
            "\n",
            "CONTENTS\n",
            "\n",
            "\n",
            "     Book the First--Recalled to Life\n",
            "\n",
            "     CHAPTER I \n",
            "The dataset contains 2165111 characters.\n",
            "The dataset contains 96 unique characters.\n"
          ]
        }
      ],
      "source": [
        "# Solution\n",
        "print(text[:1000])\n",
        "print('The dataset contains {} characters.'.format(len(text)))\n",
        "unique_chars = sorted(set(text))\n",
        "print('The dataset contains {} unique characters.'.format(len(unique_chars)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae1639f5ecfe587",
      "metadata": {
        "collapsed": false,
        "id": "3ae1639f5ecfe587"
      },
      "source": [
        "## 1.2 Text Pre-Processing (4 Marks)\n",
        "\n",
        "To prepare the dataset for training, we need to clean the text and create a numerical representation the model can interpret. Perform the following pre-processing steps:\n",
        "\n",
        "*   Convert the entire text to lowercase.\n",
        "*   Use the `Tokenizer` class from the `keras.preprocessing.text` module to tokenize the text. You should fit the tokenizer on the text and then convert the text to a sequence of numbers. You can use the `texts_to_sequences` method to do this.\n",
        "\n",
        "**Note**:\n",
        "* You'll need to specify an appropriate size for the vocabulary. The number of words in the list of most common words can serve as a guide - does it seem like a reasonable vocabulary size?\n",
        "* Some of the words will be excluded from the vocabulary, as they don't appear often enough. It's important to provide a value for `oov_token` when creating the Tokenizer instance, so that these words can be represented as \"unknown\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4d0d30cd98ea453c",
      "metadata": {
        "id": "4d0d30cd98ea453c"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "VOCAB_SIZE = 2000\n",
        "OOV_TOKEN = \"<unknown>\"\n",
        "\n",
        "# Convert the entire text to lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=OOV_TOKEN)\n",
        "tokenizer.fit_on_texts([text])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d32bb9356f711",
      "metadata": {
        "collapsed": false,
        "id": "89d32bb9356f711"
      },
      "source": [
        "If everything worked, the following line should show you the first 10 words in the vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6a7cd547a19feece",
      "metadata": {
        "id": "6a7cd547a19feece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('<unknown>', 1), ('the', 2), ('and', 3), ('of', 4), ('to', 5), ('a', 6), ('in', 7), ('’', 8), ('his', 9), ('he', 10)]\n"
          ]
        }
      ],
      "source": [
        "print(list(tokenizer.word_index.items())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da504e4bc6617613",
      "metadata": {
        "collapsed": false,
        "id": "da504e4bc6617613"
      },
      "source": [
        "## 1.3 Sequence Generation (3 Marks)\n",
        "\n",
        "Now that the text has been tokenized, we need to create sequences the model can be trained on. There are two parts to this:\n",
        "\n",
        "*   Use the `texts_to_sequences` method from the tokenizer to convert the text to a list of sequences of numbers.\n",
        "*   Generate the training sequences. Each training sequence should contain `SEQ_LENGTH` token IDs from the text. The target token for each sequence should be the word that follows the sequence in the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "4ff5fc8d0273709c",
      "metadata": {
        "id": "4ff5fc8d0273709c"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "SEQ_LENGTH = 10\n",
        "\n",
        "\n",
        "# Convert the text to a list of sequences of numbers\n",
        "sequences = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "# Generate the training sequences\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "i=0\n",
        "while i+SEQ_LENGTH+1 < len(sequences):\n",
        "    x_seq = sequences[i:i+SEQ_LENGTH]\n",
        "    i = i+SEQ_LENGTH\n",
        "    y_seq = sequences[i]\n",
        "    i += 1\n",
        "    X.append(x_seq)\n",
        "    y.append(y_seq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b6bdc0deb930df1",
      "metadata": {
        "collapsed": false,
        "id": "3b6bdc0deb930df1"
      },
      "source": [
        "Assuming your sequences are stored in `X` and the corresponding targets in `y`, the following line should print the first training sequence and its target:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a495cab04001ce92",
      "metadata": {
        "id": "a495cab04001ce92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequence: [2, 240, 220, 1359, 4, 6, 1448, 4, 88, 1]\n",
            "Target: 32\n",
            "Translated back to words: ['the', 'project', 'gutenberg', 'ebook', 'of', 'a', 'tale', 'of', 'two', '<unknown>'] -> by\n"
          ]
        }
      ],
      "source": [
        "print(f'Sequence: {X[0]}\\nTarget: {y[0]}')\n",
        "print(f'Translated back to words: {[tokenizer.index_word[i] for i in X[0]]} -> {tokenizer.index_word[y[0]]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5bb2c55da17aaa0",
      "metadata": {
        "collapsed": false,
        "id": "d5bb2c55da17aaa0"
      },
      "source": [
        "And the following code will transform y into a one-hot encoded matrix, and split everything into training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "3a929b2e6c2cc921",
      "metadata": {
        "id": "3a929b2e6c2cc921"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "boolean index did not match indexed array along dimension 1; dimension is 10 but corresponding boolean dimension is 2000",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[152], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# One last thing: let's drop any examples where the target is the OOV token - we don't want our model to predict that (boring!)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m mask \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m!=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mword_index[OOV_TOKEN]\n\u001b[0;32m---> 11\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m y[mask]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# One-hot encode the target token\u001b[39;00m\n",
            "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 1; dimension is 10 but corresponding boolean dimension is 2000"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Convert X and y to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# One last thing: let's drop any examples where the target is the OOV token - we don't want our model to predict that (boring!)\n",
        "mask = y != tokenizer.word_index[OOV_TOKEN]\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# One-hot encode the target token\n",
        "y = to_categorical(y, num_classes=VOCAB_SIZE)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e4161897210434",
      "metadata": {
        "collapsed": false,
        "id": "b6e4161897210434"
      },
      "source": [
        "# 2. Model Development (10 Marks)\n",
        "\n",
        "With the dataset prepared, it's time to develop the RNN model. You'll need to define the architecture of the model, compile it, and prepare it for training.\n",
        "\n",
        "## 2.1 Model Architecture (4 Marks)\n",
        "\n",
        "Define the architecture of your RNN model. You can design it however you like, but there are a few features that it's important to include:\n",
        "\n",
        "*   An embedding layer that learns a dense representation of the input tokens. You'll need to specify the input dimension (the size of the vocabulary) and the output dimension (the size of the dense representation). Remember, you can look at the documentation [here](https://keras.io/api/layers/core_layers/embedding/).\n",
        "*   At least one recurrent layer. We have learned how to use LSTM layers in class, but you can use other types of recurrent layers if you prefer. You can find the documentation [here](https://keras.io/api/layers/recurrent_layers/lstm/).\n",
        "*   A dense layer with a softmax activation function. This layer will output a probability distribution over the vocabulary, so that the model can make predictions about the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "9fdfaad93818fc8d",
      "metadata": {
        "id": "9fdfaad93818fc8d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_30 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m128,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_61 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_62 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m394,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │       \u001b[38;5;34m514,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,208,912</span> (4.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,208,912\u001b[0m (4.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,208,912</span> (4.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,208,912\u001b[0m (4.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, InputLayer\n",
        "\n",
        "model = Sequential([\n",
        "    InputLayer(shape=X_train[0].shape),\n",
        "    Embedding(VOCAB_SIZE, 64),\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(256),\n",
        "    Dense(VOCAB_SIZE, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fafd2dbb0d589fc",
      "metadata": {
        "collapsed": false,
        "id": "2fafd2dbb0d589fc"
      },
      "source": [
        "## 2.2 Model Compilation (3 Marks)\n",
        "\n",
        "Compile the model with an appropriate loss function and optimizer. You might also want to track additional metrics, such as accuracy.\n",
        "\n",
        "Give a short explanation of your choice of loss function and optimizer:\n",
        "\n",
        "_your explanation here_\n",
        "\n",
        "_Choosing categorical focal cross entropy as the loss function because we have a multi class classification problem with class imbalances._\n",
        "\n",
        "_Choosing Adam as the optimizer because it generally works well even with bad initialization_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "ae4ca7a12051b1fd",
      "metadata": {
        "id": "ae4ca7a12051b1fd"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_focal_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.01),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2f0b90a448c4f4b",
      "metadata": {
        "collapsed": false,
        "id": "c2f0b90a448c4f4b"
      },
      "source": [
        "## 2.3 Model Training (3 Marks)\n",
        "\n",
        "Train the model on the training data you've prepared.\n",
        "\n",
        "* Train your model for 5 epochs with a batch size of 128. Use the validation data for validation.\n",
        "* Store the training history in a variable called `history`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "256b1ea138c67ef7",
      "metadata": {
        "id": "256b1ea138c67ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0536 - loss: 1.5668 - val_accuracy: 0.0681 - val_loss: 1.4529\n",
            "Epoch 2/5\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0726 - loss: 1.4086 - val_accuracy: 0.0902 - val_loss: 1.4094\n",
            "Epoch 3/5\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0933 - loss: 1.3507 - val_accuracy: 0.1013 - val_loss: 1.3941\n",
            "Epoch 4/5\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1089 - loss: 1.3052 - val_accuracy: 0.0992 - val_loss: 1.3806\n",
            "Epoch 5/5\n",
            "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1134 - loss: 1.2760 - val_accuracy: 0.1061 - val_loss: 1.3761\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=5,\n",
        "    batch_size=128\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "195c59bf80d2a2c4",
      "metadata": {
        "collapsed": false,
        "id": "195c59bf80d2a2c4"
      },
      "source": [
        "Plot the training history to visualize the model's learning progress. Your plot should include the training and validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "9e8cacec70d8f313",
      "metadata": {
        "id": "9e8cacec70d8f313"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss')"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Solution\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation_loss')\n",
        "plt.ylim(0, 2)\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d9ed71305787aed",
      "metadata": {
        "collapsed": false,
        "id": "3d9ed71305787aed"
      },
      "source": [
        "# 3. Text Generation (10 Marks)\n",
        "\n",
        "## Task Overview\n",
        "\n",
        "In this task, you will write a function called `generate_text` that uses a trained RNN model to generate new text based on a given seed phrase.\n",
        "\n",
        "Your function **must** follow a structured approach to text generation, where the model predicts one word at a time, adds it to the sequence, and repeats this process until a desired length is reached.\n",
        "\n",
        "## Function Requirements\n",
        "\n",
        "You need to implement a function with the following signature:\n",
        "\n",
        "```python\n",
        "def generate_text(model, tokenizer, seed_text, max_sequence_len, n_words=100):\n",
        "```\n",
        "\n",
        "### **Parameters**\n",
        "- `model`: The trained RNN model that will generate text.\n",
        "- `tokenizer`: The tokenizer used to convert words to numerical sequences.\n",
        "- `seed_text`: The initial text that will be used to start generating words.\n",
        "- `max_sequence_len`: The maximum length of input sequences (same as used in training).\n",
        "- `n_words` (optional, default=100): The number of words to generate.\n",
        "\n",
        "### **Expected Output**\n",
        "- A single **string** containing the generated text.\n",
        "\n",
        "---\n",
        "\n",
        "## **Step-by-Step Instructions**\n",
        "\n",
        "### **1. Tokenize the seed text**\n",
        "Use the tokenizer to convert `seed_text` into a sequence of numbers:\n",
        "\n",
        "```python\n",
        "encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "```\n",
        "\n",
        "### **2. Pad the sequence to match training input length**\n",
        "Ensure that the sequence is the correct length by padding it **at the beginning**:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoded = pad_sequences([encoded], maxlen=max_sequence_len, truncating='pre')\n",
        "```\n",
        "\n",
        "### **3. Predict the next word**\n",
        "Pass the padded sequence to the model to predict the next word.\n",
        "\n",
        "- The model will output a probability distribution over the vocabulary.\n",
        "- Use `np.random.choice` or `np.argmax` to select the most likely word.\n",
        "\n",
        "```python\n",
        "yhat = model.predict(encoded, verbose=0)\n",
        "predicted_word_index = np.argmax(yhat)  # Select the word with the highest probability\n",
        "```\n",
        "\n",
        "### **4. Convert the predicted word index to a word**\n",
        "Find the corresponding word in the tokenizer’s vocabulary:\n",
        "\n",
        "```python\n",
        "out_word = tokenizer.index_word[predicted_word_index]\n",
        "```\n",
        "\n",
        "### **5. Append the new word to the generated text**\n",
        "- Add the predicted word to `seed_text`.\n",
        "- Repeat the process to generate multiple words.\n",
        "\n",
        "```python\n",
        "seed_text += \" \" + out_word\n",
        "```\n",
        "\n",
        "### **6. Repeat Steps 3-5 until `n_words` have been generated**\n",
        "\n",
        "- Each time, remove the oldest word from the input sequence to keep its length constant.\n",
        "- Continue generating words one at a time until reaching `n_words`.\n",
        "\n",
        "---\n",
        "\n",
        "## **Important Notes**\n",
        "- If the generated text doesn’t make much sense, don’t worry! The quality will improve as the model is trained better.\n",
        "- This is a **challenging** task! If you get stuck, ask for help.\n",
        "- The `generate_text` function should return the **full generated text as a single string**.\n",
        "\n",
        "### **Example Usage**\n",
        "After implementing `generate_text`, you should be able to call it like this:\n",
        "\n",
        "```python\n",
        "generated_text = generate_text(model, tokenizer, \"Once upon a time\", max_sequence_len=20, n_words=50)\n",
        "print(generated_text)\n",
        "```\n",
        "\n",
        "This should output a string of 50 words generated by the model, starting with `\"Once upon a time\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "d73dbf278a1265ef",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-08T21:38:43.251561Z",
          "start_time": "2024-02-08T21:38:20.349248Z"
        },
        "id": "d73dbf278a1265ef"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def generate_text(model, tokenizer, seed_text, max_sequence_len, n_words=100):\n",
        "    words = seed_text.split(\" \")\n",
        "    current_word_count = len(words)\n",
        "\n",
        "    while current_word_count < n_words:\n",
        "        encoded = tokenizer.texts_to_sequences(words)[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_sequence_len, truncating='pre')\n",
        "        \n",
        "        yhat = model.predict(encoded, verbose=0)\n",
        "        predicted_word_index = np.random.choice([i for i in range(1, VOCAB_SIZE+1)], p=yhat[0])\n",
        "        out_word = tokenizer.index_word[predicted_word_index]\n",
        "        seed_text += \" \" + out_word\n",
        "        words.append(out_word)\n",
        "        words.pop(0)\n",
        "        current_word_count += 1\n",
        "\n",
        "    return seed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "f253c868",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Once upon a time pickwick stopped least them mr a in seemed direction dowler was as ' pickwick as and are better and and 1 ‘well man be pair be and may of ” man worth and his feel when short period said were care seat in pretty of to and was and ” man a found you said last in no and interposed not our and said be through bed and mr and ” man town dragged you pickwick that and don’t very with over ” sawyer on her year ” while something your you ‘well of but you\""
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(model, tokenizer, 'Once upon a time', SEQ_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "f463b0c3df49e2c",
      "metadata": {
        "id": "f463b0c3df49e2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hamlet to along said and answered and clothes magnus a never this your without be a surprised had and is serjeant it mr fogg what for ’ this always into back she are and doors at and three them pickwick every of and in through and on and in not mr exclaimed and his speed all had resumed and in be whole around few come for stopped then and little mother a trouble i everything street fell glancing his might houses up sir of as is and boy were day so hands that and might too pickwick you their drinking'"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test the text generation function\n",
        "generate_text(model, tokenizer, 'hamlet', SEQ_LENGTH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5871d836a0135c41",
      "metadata": {
        "collapsed": false,
        "id": "5871d836a0135c41"
      },
      "source": [
        "# 4. Model Refinement (5 Marks)\n",
        "\n",
        "## **Understanding Your Model's Performance**\n",
        "\n",
        "At this stage, you might have noticed that the text generated by your model doesn’t make much sense yet. **This is completely expected!**\n",
        "\n",
        "There are a few reasons why:\n",
        "1. **RNNs have limitations** – While they can generate sequences, they struggle with long-range dependencies in text.\n",
        "2. **Character-by-character generation is outdated** – Modern models like ChatGPT don’t generate text one letter at a time. Instead, they use **tokens**, which represent larger chunks of words, making their outputs much more coherent.\n",
        "3. **Training time and data size** – Our model has been trained on a relatively small dataset for a short period of time, which means it hasn’t learned enough patterns to generate meaningful text.\n",
        "\n",
        "Even though we don’t expect ChatGPT-level performance, this exercise is about **experimentation, not perfection**. Your goal here is to try **at least one** way to refine your model and observe how it affects the output.\n",
        "\n",
        "---\n",
        "\n",
        "## **Refining Your Model**\n",
        "There are many ways to try improving your model. Here are some ideas:\n",
        "\n",
        "✅ **Use pre-trained embeddings**  \n",
        "   Instead of learning word representations from scratch, you can use pre-trained word embeddings. This allows your model to start with a better understanding of word relationships.\n",
        "\n",
        "✅ **Modify the model architecture**  \n",
        "   - Experiment with **more layers** or different numbers of units per layer.  \n",
        "   - Try adding **dropout layers** to prevent overfitting.  \n",
        "   - Consider using **bidirectional RNNs**, which process text in both forward and backward directions.  \n",
        "\n",
        "✅ **Train for longer**  \n",
        "   - Try increasing the number of **epochs** (but be mindful of overfitting).  \n",
        "   - Experiment with different **batch sizes** to see if they affect training stability.  \n",
        "\n",
        "Again, **perfection is NOT the goal here** – we just want to see that you experimented with improving your model! 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "dda8b0f845c20862",
      "metadata": {
        "id": "dda8b0f845c20862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-09 19:26:21--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2025-03-09 19:29:01 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "e8b777220505635",
      "metadata": {
        "id": "e8b777220505635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained embeddings\n",
        "embeddings_index = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f'Found {len(embeddings_index)} word vectors.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "d3e48ff004757cf2",
      "metadata": {
        "id": "d3e48ff004757cf2"
      },
      "outputs": [],
      "source": [
        "# Create an embedding matrix\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, 100))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < VOCAB_SIZE:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "e3d21d5dbbbcf9f9",
      "metadata": {
        "id": "e3d21d5dbbbcf9f9"
      },
      "outputs": [],
      "source": [
        "embedding_layer = Embedding(\n",
        "    VOCAB_SIZE, 100, weights=[embedding_matrix], trainable=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "f16570310f0f56b",
      "metadata": {
        "id": "f16570310f0f56b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_60\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_60\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_101               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_102               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,400</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_32 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m200,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m64,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_101               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m788,480\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_102               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m4,198,400\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_117 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_118 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m2,099,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_119 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)           │     \u001b[38;5;34m4,098,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,497,808</span> (47.68 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,497,808\u001b[0m (47.68 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,297,808</span> (46.91 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,297,808\u001b[0m (46.91 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,000</span> (781.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m200,000\u001b[0m (781.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Solution\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, Bidirectional, InputLayer\n",
        "\n",
        "model = Sequential([\n",
        "    InputLayer(shape=X_train[0].shape),\n",
        "    embedding_layer,\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    Bidirectional(LSTM(256, return_sequences=True)),\n",
        "    Bidirectional(LSTM(512)),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(2048, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(VOCAB_SIZE, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_focal_crossentropy',\n",
        "    optimizer=Adam(learning_rate=3e-4),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "4e362b51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.0620 - loss: 1.5547 - val_accuracy: 0.0681 - val_loss: 1.4534\n",
            "Epoch 2/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.0660 - loss: 1.4411 - val_accuracy: 0.0878 - val_loss: 1.4203\n",
            "Epoch 3/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.0903 - loss: 1.3746 - val_accuracy: 0.1056 - val_loss: 1.3720\n",
            "Epoch 4/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1082 - loss: 1.3168 - val_accuracy: 0.1080 - val_loss: 1.3567\n",
            "Epoch 5/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1140 - loss: 1.2790 - val_accuracy: 0.1126 - val_loss: 1.3491\n",
            "Epoch 6/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1204 - loss: 1.2483 - val_accuracy: 0.1154 - val_loss: 1.3466\n",
            "Epoch 7/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1293 - loss: 1.2159 - val_accuracy: 0.1151 - val_loss: 1.3514\n",
            "Epoch 8/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1366 - loss: 1.1837 - val_accuracy: 0.1166 - val_loss: 1.3569\n",
            "Epoch 9/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1454 - loss: 1.1535 - val_accuracy: 0.1197 - val_loss: 1.3561\n",
            "Epoch 10/10\n",
            "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1515 - loss: 1.1243 - val_accuracy: 0.1181 - val_loss: 1.3782\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "id": "27e35468",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss')"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation_loss')\n",
        "plt.ylim(0, 2)\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "id": "ae362e2dd29be2e1",
      "metadata": {
        "id": "ae362e2dd29be2e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"hamlet rather former shall this difficulty in minutes a take that your come tone of whom will far returned back heard winkle good it’s show hand was mrs but my drew he sam look cold when which while little shall is make short quickly fire a word set back ’ above manner of down any fat till jinks thing him pale north very pross his say and fingers want be snodgrass ' table sam 1 goblin at she sudden darnay him daughter beside of were brothers your do brought did this samuel too days ' more went appearance i young\""
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test the text generation function\n",
        "generate_text(model, tokenizer, 'hamlet', SEQ_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236cb723e4e5b3fc",
      "metadata": {
        "id": "236cb723e4e5b3fc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
